---
title: "p8105_hw5_ys3298"
author: "Yimeng SHANG"
date: "11/1/2019"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


# PROBLEM1

```{r echo=FALSE}
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

```

```{r message=FALSE}
#Write a function 
missing_value = function(vec) {
  if (is.numeric(vec)) {
    m = round(mean(vec, na.rm = TRUE), 1)
    output = vec %>% replace_na(m)
  } else if (is.character(vec)) {
    output = vec %>% replace_na("virginica")
  } else {
    stop("Error in type")
  }
  return(output)
}

#Apply this function to the columns of iris_with_missing using a map statement
map(iris_with_missing, missing_value) %>%
  bind_cols()
```


# PROBLEM2

```{r echo=TRUE, message=FALSE}
# create a tidy dataframe
filename = list.files("./data") 
data_path = paste("./data", filename, sep = "/")

names = data_frame(filename = filename)

data =
  data_path %>%
  map(read_csv) %>%     
  reduce(rbind) %>% 
  cbind(names) %>% 
  separate(col = filename, into = c("group","ID_csv"), sep = "_") %>% 
  mutate(ID = str_replace(ID_csv,".csv","")) %>% 
  select(group, ID, everything()) %>% 
  select(-ID_csv) %>% 
  janitor::clean_names() 

data %>%  knitr::kable()

# tidy the result
clean_data = data %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix ="week_",
    values_to = "observations"
  )

clean_data 
```

```{r echo=TRUE}
# plot
clean_data %>% 
  ggplot(aes(x = week, y = observations)) + geom_line(aes(group = id,color = id)) + labs(title = "observations on each subject over time") +
  facet_grid(.~group)
```

From the plots, we can see the overall observations in experimental group are higher than the control group. The observation for each day in a week flactuated a lot but basiclly remains at the same level for control group, wheras the observations increases by days for observation group.

# PROBLEM3

```{r echo=TRUE}
set.seed(1)

model = function(beta1 = 0) {
  x = rnorm(30, 0, 1)
  epi = rnorm(30, 0, sd = sqrt(50))
  y = 2 + beta1 * x + epi
  data = tibble(x = x, y = y)
  
  ls_fit = lm(y ~ x, data) %>% 
    broom::tidy()
  
  return(tibble(beta1 = pull(ls_fit,estimate)[[2]], p = pull(ls_fit,p.value)[[2]]))
}

n = 10000

sim_results = 
  rerun(n, model(0)) %>%  ## rerun
  bind_rows()

sim_all = 
  tibble(beta1_true = c(1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output_list = map(.x = beta1_true, ~rerun(n, model(beta1 = .x)))) %>%
  unnest %>% 
  unnest
```

```{r}
proportion =
  sim_all %>% 
  filter(p < 0.05) %>% 
  group_by(beta1_true) %>% 
  summarize(proportion = n()/n) 

proportion %>% 
  ggplot(aes(x = beta1_true, y = proportion)) + geom_point(color = "blue", size = 5) + geom_line(color = "blue") +
  labs(x = "beta1", y = "Power(proportion of reject)", title = "Association between effect size and power")
```
**Describe the association between effect size and power:** Form the plot, we can see there is a linear relationship between power and size effect. Power increases with the increase of size effect.

```{r}
beta1_true_average = 
  sim_all %>% 
  group_by(beta1_true) %>% 
  summarize(average = mean(beta1)) 

beta1_reject_average =
  sim_all %>% 
  filter(p < 0.05) %>% 
  group_by(beta1_true) %>% 
  summarize(average_reject = mean(beta1)) 

all_info = left_join(beta1_true_average,beta1_reject_average) 
  
all_info %>% 
  ggplot(aes(x = beta1_true)) + 
  geom_point(aes(y = average, color = "pink"), size = 5) +
  geom_line(aes(y = average, color = "pink")) + 
  geom_point(aes(y = average_reject, color = "blue"), size = 5) +
  geom_line(aes(y = average_reject, color = "blue")) +
  scale_color_identity(breaks = c("pink", "blue"),
                       labels = c("True values", "Rejected values"),
                       guide = "legend") +
  labs(
    title = "Estimate Beta1 Vs True Beta1",
    x = "True Beta1",
    y = "Average Beta1"
  ) 
```

The sample average of beta1_hat across tests for which the null is rejected is not approximately equal to the true value of beta1.

Because the null here is beta1 = 0. When we reject the null, we get result from beta1 not equal to 0. As the real beta1 increases, the difference between these two will converge.


